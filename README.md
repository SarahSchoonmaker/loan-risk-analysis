
# ðŸ›¡ï¸ **Loan Fraud Detection Pipeline**

A production-ready pipeline for detecting **fraudulent or incomplete commercial loan applications**. It validates OCR-extracted documents, checks for inconsistencies (e.g., income mismatch, falsified addresses), and surfaces risks via real-time analytics dashboards.

---

## ðŸ”§ **Technologies Used**

### ðŸ Backend & Data Processing

* **Python** â€“ Core pipeline logic and orchestration
* **spaCy** â€“ NLP for address verification and entity extraction
* **pandas** â€“ Data wrangling and tabular processing
* **psycopg2 / SQLAlchemy** â€“ PostgreSQL interaction
* **boto3** â€“ AWS SDK for S3/Glue integration

### â˜ï¸ AWS Stack

* **Amazon S3** â€“ Loan document storage (CSV, JSON)
* **AWS Glue** â€“ Schema crawler & optional ETL
* **Amazon Athena** â€“ Serverless SQL over S3
* **Amazon Redshift Serverless** â€“ Analytics warehouse
* **IAM** â€“ Role-based access control

### ðŸ“Š Visualization

* **Amazon Redshift Query Editor v2** â€“ SQL exploration/debugging
* **Streamlit** â€“ Interactive dashboards

---

## ðŸ“ **Project Structure**

```text
loan-fraud-pipeline/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Entry point
â”‚   â”œâ”€â”€ redshift.py          # Redshift query helpers
â”‚   â”œâ”€â”€ validation.py        # Fraud logic (e.g., income mismatch)
â”‚   â”œâ”€â”€ nlp_utils.py         # Address NLP checks (spaCy)
â”‚   â””â”€â”€ config.py            # Env and credential loading
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_outputs/      # Mock output examples
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## âš™ï¸ **Running Locally**

### 1. Clone the Repo

```bash
git clone https://github.com/sarahschoonmaker/loan-fraud-pipeline.git
cd loan-fraud-pipeline
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

### 3. Configure Environment Variables

Create a `.env` file with:

```env
DB_HOST=localhost
DB_PORT=5432
DB_NAME=loan_fraud
DB_USER=postgres
DB_PASSWORD=yourpassword

AWS_ACCESS_KEY_ID=your-key
AWS_SECRET_ACCESS_KEY=your-secret
AWS_REGION=your-region
```

### 4. Run the Pipeline

```bash
python app/main.py
```

---

## ðŸ—ï¸ **Architecture Overview**

```text
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Loan CSVs  â”‚
                â”‚   (S3)     â”‚
                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚      AWS Glue Crawler         â”‚
     â”‚   Extract schema from S3      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Athena / Redshift Queries â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                    â”‚                          â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
     â”‚   Python Validation Layer â”‚             â”‚
     â”‚ - Income comparison       â”‚             â”‚
     â”‚ - NLP address match       â”‚             â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                    â”‚                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
        â”‚  Dashboard (Streamlit)  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… **Fraud Detection Rules**

* **Income mismatch** â€“ >30% difference between declared and OCR-derived income
* **Address mismatch** â€“ Fuzzy match score < 80% between OCR and provided address
* **Invalid ZIP/Location** â€“ Zip doesn't match city/state via NLP or geodata
* **Missing fields** â€“ Required values absent in OCR results

---

## ðŸ” **Sample Query (Redshift)**

```sql
SELECT loan_id, business_name
FROM loan_applications
WHERE ABS(income - doc_income) > income * 0.3;
```

